# 🚀 Task 1: Big Data Analysis Using Dask
## 🎯 Objective
Analyze a large dataset using **Dask** to demonstrate scalability in big data processing.
## 📚 Tools & Technologies
- Python  
- **Dask** (Parallel Computing)  
- Matplotlib (Visualization)  
## 📝 Task Description
- Processed and analyzed a **large-scale NYC taxi dataset** using Dask.
- Focused on analyzing **payment types** to derive insights.
- Visualized results through bar charts.
## 📥 Dataset Source
The dataset `yellow_tripdata_2019-01.csv` is too large for GitHub.
You can download it from the official NYC TLC website:
➡️ [NYC TLC Trip Record Data](https://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)
Or from Kaggle:
➡️ [NYC Yellow Taxi Trip Data on Kaggle](https://www.kaggle.com/datasets/new-york-city/nyc-taxi-trip-data)
## 📊 Key Outcomes
- Handled millions of rows efficiently with **Dask DataFrame**.
- Identified trends in NYC taxi **payment methods**.
- Visualized results with **Matplotlib**.
## 🗂️ Files Included
Task1_BigData_Dask.ipynb    # Jupyter Notebook with step-by-step analysis
yellow_tripdata_2019-01.csv # Dataset used
README.md                   # This file
