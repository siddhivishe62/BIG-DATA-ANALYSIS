# ğŸš€ Task 1: Big Data Analysis Using Dask
## ğŸ¯ Objective
Analyze a large dataset using **Dask** to demonstrate scalability in big data processing.
## ğŸ“š Tools & Technologies
- Python  
- **Dask** (Parallel Computing)  
- Matplotlib (Visualization)  
## ğŸ“ Task Description
- Processed and analyzed a **large-scale NYC taxi dataset** using Dask.
- Focused on analyzing **payment types** to derive insights.
- Visualized results through bar charts.
## ğŸ“¥ Dataset Source
The dataset `yellow_tripdata_2019-01.csv` is too large for GitHub.
You can download it from the official NYC TLC website:
â¡ï¸ [NYC TLC Trip Record Data](https://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)
Or from Kaggle:
â¡ï¸ [NYC Yellow Taxi Trip Data on Kaggle](https://www.kaggle.com/datasets/new-york-city/nyc-taxi-trip-data)
## ğŸ“Š Key Outcomes
- Handled millions of rows efficiently with **Dask DataFrame**.
- Identified trends in NYC taxi **payment methods**.
- Visualized results with **Matplotlib**.
## ğŸ—‚ï¸ Files Included
Task1_BigData_Dask.ipynb    # Jupyter Notebook with step-by-step analysis
yellow_tripdata_2019-01.csv # Dataset used
README.md                   # This file
